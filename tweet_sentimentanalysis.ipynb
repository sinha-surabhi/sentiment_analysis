{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14640"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "tweets = pd.read_csv(r\"C:\\Users\\SURABHI\\PycharmProjects\\Tweets.csv\")\n",
    "list(tweets.columns.values)\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    9178\n",
      "neutral     3099\n",
      "positive    2363\n",
      "Name: airline_sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                  @VirginAmerica What @dhepburn said.\n",
       "1    @VirginAmerica plus you've added commercials t...\n",
       "2    @VirginAmerica I didn't today... Must mean I n...\n",
       "3    @VirginAmerica it's really aggressive to blast...\n",
       "4    @VirginAmerica and it's a really big bad thing...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_counts = tweets.airline_sentiment.value_counts()  #Series.value_counts returns objects containg count of unique values.o/p is in descending order.\n",
    "number_of_tweets = tweets.tweet_id.count()  \n",
    "print(sentiment_counts)\n",
    "tweets.text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'airline', 'like']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def normalizer(tweet):\n",
    "    only_letters = re.sub(\"[^a-zA-Z]\", \" \",tweet) \n",
    "    tokens = nltk.word_tokenize(only_letters)[2:]\n",
    "    lower_case = [l.lower() for l in tokens]\n",
    "    filtered_result = list(filter(lambda l: l not in stop_words, lower_case))\n",
    "    lemmas = [wordnet_lemmatizer.lemmatize(t) for t in filtered_result]\n",
    "    return lemmas\n",
    "normalizer(\"Here is text about an airline I like.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>normalized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>[dhepburn, said]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>[added, commercial, experience, tacky]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>[today, must, mean, need, take, another, trip]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "      <td>[really, aggressive, blast, obnoxious, entertainment, guest, face, amp, little, recourse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>[really, big, bad, thing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                             text  \\\n",
       "0  @VirginAmerica What @dhepburn said.                                                                                              \n",
       "1  @VirginAmerica plus you've added commercials to the experience... tacky.                                                         \n",
       "2  @VirginAmerica I didn't today... Must mean I need to take another trip!                                                          \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
       "4  @VirginAmerica and it's a really big bad thing about it                                                                          \n",
       "\n",
       "                                                                            normalized_tweet  \n",
       "0  [dhepburn, said]                                                                           \n",
       "1  [added, commercial, experience, tacky]                                                     \n",
       "2  [today, must, mean, need, take, another, trip]                                             \n",
       "3  [really, aggressive, blast, obnoxious, entertainment, guest, face, amp, little, recourse]  \n",
       "4  [really, big, bad, thing]                                                                  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1) # Setting this so we can see the full content of cells\n",
    "tweets['normalized_tweet'] = tweets.text.apply(normalizer)\n",
    "tweets[['text','normalized_tweet']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[dhepburn said]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[added commercial, commercial experience, experience tacky, added commercial experience, commercial experience tacky]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[today must, must mean, mean need, need take, take another, another trip, today must mean, must mean need, mean need take, need take another, take another trip]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[really aggressive, aggressive blast, blast obnoxious, obnoxious entertainment, entertainment guest, guest face, face amp, amp little, little recourse, really aggressive blast, aggressive blast obnoxious, blast obnoxious entertainment, obnoxious entertainment guest, entertainment guest face, guest face amp, face amp little, amp little recourse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[really big, big bad, bad thing, really big bad, big bad thing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                        grams\n",
       "0  [dhepburn said]                                                                                                                                                                                                                                                                                                                                           \n",
       "1  [added commercial, commercial experience, experience tacky, added commercial experience, commercial experience tacky]                                                                                                                                                                                                                                     \n",
       "2  [today must, must mean, mean need, need take, take another, another trip, today must mean, must mean need, mean need take, need take another, take another trip]                                                                                                                                                                                          \n",
       "3  [really aggressive, aggressive blast, blast obnoxious, obnoxious entertainment, entertainment guest, guest face, face amp, amp little, little recourse, really aggressive blast, aggressive blast obnoxious, blast obnoxious entertainment, obnoxious entertainment guest, entertainment guest face, guest face amp, face amp little, amp little recourse]\n",
       "4  [really big, big bad, bad thing, really big bad, big bad thing]                                                                                                                                                                                                                                                                                           "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "def ngrams(input_list):\n",
    "    #onegrams = input_list\n",
    "    bigrams = [' '.join(t) for t in list(zip(input_list, input_list[1:]))]\n",
    "    trigrams = [' '.join(t) for t in list(zip(input_list, input_list[1:], input_list[2:]))]\n",
    "    return bigrams+trigrams\n",
    "tweets['grams'] = tweets.normalized_tweet.apply(ngrams)\n",
    "tweets[['grams']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http co', 449),\n",
       " ('customer service', 438),\n",
       " ('cancelled flightled', 425),\n",
       " ('late flight', 215),\n",
       " ('cancelled flighted', 196),\n",
       " ('flight cancelled', 185),\n",
       " ('late flightr', 144),\n",
       " ('cancelled flight', 131),\n",
       " ('hold hour', 128),\n",
       " ('flightled flight', 123),\n",
       " ('flight cancelled flightled', 117),\n",
       " ('flight delayed', 115),\n",
       " ('cancelled flightled flight', 107),\n",
       " ('call back', 106),\n",
       " ('booking problem', 98),\n",
       " ('gate agent', 83),\n",
       " ('flight flight', 74),\n",
       " ('hour late', 69),\n",
       " ('delayed flight', 69),\n",
       " ('flight attendant', 60)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "def count_words(input):\n",
    "    cnt = collections.Counter()\n",
    "    for row in input:\n",
    "        for word in row:\n",
    "            cnt[word] += 1\n",
    "    return cnt\n",
    "\n",
    "tweets[(tweets.airline_sentiment == 'negative')][['grams']].apply(count_words)['grams'].most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http co', 233),\n",
       " ('customer service', 91),\n",
       " ('flight attendant', 25),\n",
       " ('quick response', 19),\n",
       " ('great flight', 17),\n",
       " ('best airline', 16),\n",
       " ('great job', 16),\n",
       " ('great service', 16),\n",
       " ('gate agent', 16),\n",
       " ('booking problem', 15),\n",
       " ('thanks help', 15),\n",
       " ('thank much', 15),\n",
       " ('good work', 14),\n",
       " ('fleet fleek', 14),\n",
       " ('fleek http', 14),\n",
       " ('fleet fleek http', 14),\n",
       " ('fleek http co', 14),\n",
       " ('guy rock', 13),\n",
       " ('looking forward', 13),\n",
       " ('great customer', 12)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[(tweets.airline_sentiment == 'positive')][['grams']].apply(count_words)['grams'].most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "vectorized_data = count_vectorizer.fit_transform(tweets.text)\n",
    "indexed_data = hstack((np.array(range(0,vectorized_data.shape[0]))[:,None], vectorized_data))\n",
    "\n",
    "def sentiment2target(sentiment):\n",
    "    return {\n",
    "        'negative': 0,\n",
    "        'neutral': 1,\n",
    "        'positive' : 2\n",
    "    }[sentiment]\n",
    "targets = tweets.airline_sentiment.apply(sentiment2target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test, targets_train, targets_test = train_test_split(indexed_data, targets, test_size=0.3, random_state=0)\n",
    "data_train_index = data_train[:,0]\n",
    "data_train = data_train[:,1:]\n",
    "data_test_index = data_test[:,0]\n",
    "data_test = data_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7802823315118397"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = OneVsRestClassifier(svm.SVC(gamma=0.01, C=100., probability=True, class_weight='balanced', kernel='linear'))\n",
    "clf_output = clf.fit(data_train, targets_train)\n",
    "\n",
    "\n",
    "clf.score(data_test, targets_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=clf.predict(data_test)\n",
    "#clf.accuracy_score(predict,targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12338998, 0.06470563, 0.81190439],\n",
       "       [0.12305412, 0.06915121, 0.80779467],\n",
       "       [0.96374547, 0.02521347, 0.01104107],\n",
       "       [0.90228529, 0.07836866, 0.01934605],\n",
       "       [0.97783972, 0.01091269, 0.01124759],\n",
       "       [0.50459283, 0.4534472 , 0.04195997],\n",
       "       [0.2606491 , 0.5043371 , 0.23501381]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = count_vectorizer.transform([\n",
    "    \"What a great airline, the trip was a pleasure!\",\n",
    "    \"My issue was quickly resolved after calling customer support. Thanks!\",\n",
    "    \"What the hell! My flight was cancelled again. This sucks!\",\n",
    "    \"Service was awful. I'll never fly with you again.\",\n",
    "    \"You losers lost my luggage. Never again!\",\n",
    "    \"I have mixed feelings about airlines. I don't know what I think.\",\n",
    "    \"\"\n",
    "])\n",
    "clf.predict_proba(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('testing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @OGR_EN: Critics of #humanrights legalism are right to call for more “pragmatism,” but this must be contextual, looking for advocacy hoo…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Critics of #humanrights legalism are right to call for more “pragmatism,” but this must be contextual, looking for… https://t.co/1x5kxwHsT7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>In Kenya, Guatemala and Brazil, courts have defied presidents and shaken up politics—is court-centric advocacy one… https://t.co/AimbDuG3bw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @OGR_EN: Critics of human rights legalism are right to call for more “pragmatism,” but this must be contextual, looking for advocacy hoo…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @OGR_EN: Critics of human rights legalism are right to call for more “pragmatism,” but this must be contextual, looking for advocacy hoo…</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0  0            \n",
       "1  1            \n",
       "2  2            \n",
       "3  3            \n",
       "4  4            \n",
       "\n",
       "                                                                                                                                              0  \n",
       "0  RT @OGR_EN: Critics of #humanrights legalism are right to call for more “pragmatism,” but this must be contextual, looking for advocacy hoo…  \n",
       "1  Critics of #humanrights legalism are right to call for more “pragmatism,” but this must be contextual, looking for… https://t.co/1x5kxwHsT7   \n",
       "2  In Kenya, Guatemala and Brazil, courts have defied presidents and shaken up politics—is court-centric advocacy one… https://t.co/AimbDuG3bw   \n",
       "3  RT @OGR_EN: Critics of human rights legalism are right to call for more “pragmatism,” but this must be contextual, looking for advocacy hoo…  \n",
       "4  RT @OGR_EN: Critics of human rights legalism are right to call for more “pragmatism,” but this must be contextual, looking for advocacy hoo…  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     RT @OGR_EN: Critics of #humanrights legalism are right to call for more “pragmatism,” but this must be contextual, looking for advocacy hoo…      \n",
       "1     Critics of #humanrights legalism are right to call for more “pragmatism,” but this must be contextual, looking for… https://t.co/1x5kxwHsT7       \n",
       "2     In Kenya, Guatemala and Brazil, courts have defied presidents and shaken up politics—is court-centric advocacy one… https://t.co/AimbDuG3bw       \n",
       "3     RT @OGR_EN: Critics of human rights legalism are right to call for more “pragmatism,” but this must be contextual, looking for advocacy hoo…      \n",
       "4     RT @OGR_EN: Critics of human rights legalism are right to call for more “pragmatism,” but this must be contextual, looking for advocacy hoo…      \n",
       "5     Critics of human rights legalism are right to call for more “pragmatism,” but this must be contextual, looking for… https://t.co/IitQ3m9fkF       \n",
       "6     Dustin Sharp makes a valuable @OGR_EN contribution to discussion of human rights advocacy, which must complement cu… https://t.co/xkBTyuYG9c      \n",
       "7     RT @neilmcrowther: For those interested in human rights, this is a really interesting read: Politics and pragmatism in human rights advocac…      \n",
       "8     In this context of growing authoritarianism, the human rights field needs a fundamental re-think. Dustin Sharp to… https://t.co/pU3uJQi4Zv        \n",
       "9     Politics and pragmatism in human rights advocacy | OpenGlobalRights https://t.co/VWKQFeoGKQ                                                       \n",
       "10    RT @neilmcrowther: For those interested in human rights, this is a really interesting read: Politics and pragmatism in human rights advocac…      \n",
       "11    RT @neilmcrowther: For those interested in human rights, this is a really interesting read: Politics and pragmatism in human rights advocac…      \n",
       "12    RT @neilmcrowther: For those interested in human rights, this is a really interesting read: Politics and pragmatism in human rights advocac…      \n",
       "13    For those interested in human rights, this is a really interesting read: Politics and pragmatism in human rights ad… https://t.co/8Y8FbtjAyw      \n",
       "14    Telugu Desam Party leader hacked to death in Kurnool district\\r\\nhttps://t.co/8zAYHNqtut\\r\\n#TDP #AndhraPradesh #Politics… https://t.co/AxPgEMUtVH\n",
       "15    RT @OGR_EN: To insist on the #Rohingya status as a victimized religious minority while ignoring other factors cements their position as out…      \n",
       "16    RT @OGR_EN: To insist on the #Rohingya status as a victimized religious minority while ignoring other factors cements their position as out…      \n",
       "17    To insist on the #Rohingya status as a victimized religious minority while ignoring other factors cements their pos… https://t.co/KfttpUykLb      \n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen=[]\n",
    "#for line in df.iloc[1]:\n",
    "sen=(count_vectorizer.transform(df.iloc[:,1]))\n",
    "out=clf.predict_proba(sen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
